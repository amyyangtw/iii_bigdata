{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立所有商品名稱 + 商品分類細項 的list\n",
    "\n",
    "### 1. pd.read_csv('自己的檔案路徑')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./dataset/keywords/keywords_LA1.csv')\n",
    "df_dict = df.set_index('product_name').to_dict()\n",
    "items_dict = df_dict['aisle']\n",
    "\n",
    "print(len(items_dict))\n",
    "#print(items_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得Product info Dict\n",
    "\n",
    "### 2. with open('product_info_自己負責的區.json', 'w') as fp:\n",
    "### 3. win的user 請改 soup = BeautifulSoup(req.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(search_result):\n",
    "    for item_info in search_result:\n",
    "\n",
    "        product_info = {\n",
    "            \"keyword\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"brand\": \"\",\n",
    "            \"url\": \"\",\n",
    "            \"pic\": \"\",\n",
    "            \"price\": \"\",\n",
    "            \"category\": [],\n",
    "            \"star_ratings\": [],\n",
    "            \"at_a_glance\": [],\n",
    "            \"highlights\": [],\n",
    "            \"specifications\": {},\n",
    "            \"description\": \"\",\n",
    "            \"reviews\": []\n",
    "        }\n",
    "\n",
    "        p_name = item_info.get('title', 'NA')\n",
    "        p_brand = item_info.get('brand', 'NA')\n",
    "        p_price = item_info.get('price').get('formatted_current_price', 'NA')\n",
    "        p_glances = item_info.get(\"wellness_merchandise_attributes\", 'NA')\n",
    "        p_description = item_info.get('description', 'NA')\n",
    "\n",
    "        #rating\n",
    "        p_ratings_s_avg = item_info.get('average_rating', 'NA')\n",
    "        p_ratings_s_cnt = item_info.get('total_reviews', 'NA')\n",
    "\n",
    "        p_url = lambda x: 'https://www.target.com'+x if item_info.get('url') else 'NA'\n",
    "        p_pic = lambda x: x.get('base_url')+x.get('primary') if item_info.get('images') else 'NA'\n",
    "        p_highlights = lambda x:x['soft_bullets'].get('bullets', 'NA') if item_info.get('soft_bullets') else 'NA' \n",
    "\n",
    "        #category\n",
    "        req = requests.get(p_url(item_info['url']))\n",
    "        #win的user 請改 soup = BeautifulSoup(req.text, \"lxml\")\n",
    "        soup = BeautifulSoup(req.text, \"html\")\n",
    "        p_category = soup.find(\"div\", {\"class\", \"h-text-sm h-padding-v-tiny\"}).text.strip(\"\\u200e\").split(\"/\")\n",
    "\n",
    "        #reviews\n",
    "        p_review = item_info.get(\"top_reviews\", 'NA')\n",
    "\n",
    "        product_info['keyword'] = item\n",
    "        product_info['name'] = p_name\n",
    "        product_info['url'] = p_url(item_info['url'])\n",
    "        product_info['brand'] = p_brand\n",
    "        product_info['pic'] = p_pic(item_info['images'][0])\n",
    "        product_info['price'] = p_price\n",
    "        product_info['category'] = p_category[1:]\n",
    "        product_info['star_ratings'].append(p_ratings_s_avg) \n",
    "        product_info['star_ratings'].append(p_ratings_s_cnt) \n",
    "\n",
    "        #specifications\n",
    "        spec_list = [\"Contains\", \"Form\", \"State of Readiness\", \"Store\", \"Package Quantity\", \"Package type\", \"Net weight\"]\n",
    "        if item_info.get(\"bullet_description\"):\n",
    "            for i in spec_list:\n",
    "                for j in item_info[\"bullet_description\"]:\n",
    "                    j = re.sub(\"<.*?>\", \" \",j).strip(' ')\n",
    "                    if re.match(i, j.split(\": \")[0]):\n",
    "                        product_info[\"specifications\"][i] = j.split(\": \")[1]\n",
    "        else:\n",
    "            product_info[\"specifications\"]='NA'\n",
    "\n",
    "        #description\n",
    "        product_info['description'] = p_description\n",
    "        product_info['description'] = re.sub(\"<.*?>\", \" \",product_info['description'])\n",
    "\n",
    "        #reviews\n",
    "        if (p_review == \"NA\"):\n",
    "            product_info[\"reviews\"] = \"NA\"\n",
    "        else:\n",
    "            for rev in p_review:\n",
    "                review = re.sub('[\\r\\n\\t]', '', rev[\"review_text\"])\n",
    "                product_info[\"reviews\"].append(review)\n",
    "\n",
    "        #at_a_glance\n",
    "        if (p_glances=='NA'):\n",
    "            product_info['at_a_glance']= 'NA'\n",
    "        else:\n",
    "            for glance in p_glances:\n",
    "                product_info['at_a_glance'].append(glance[\"value_name\"])\n",
    "\n",
    "        #highlight\n",
    "        if (p_highlights(item_info)=='NA'):\n",
    "            product_info['highlights'] = 'NA'\n",
    "        else:\n",
    "            for highlight in p_highlights(item_info):\n",
    "                product_info['highlights'].append(highlight)\n",
    "\n",
    "        products.append(product_info)\n",
    "        \n",
    "        with open('product_info_LA1.json', 'w', encoding='utf-8') as fp:\n",
    "            json.dump(products, fp, indent=4, ensure_ascii=False)\n",
    "            global count\n",
    "            count+=1\n",
    "            print(f'{count} finished.')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析網址 + 更改參數 get info\n",
    "\n",
    "### 4. url = '自己的地點的url' (count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'idx' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-fb5c96eacd3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s : no result'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-52d6a19f5c3a>\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(search_result)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'product_info_LA1.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{idx}\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'idx' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n",
    "\n",
    "url = 'https://redsky.target.com/v2/plp/search/?channel=web&count=6&default_purchasability_filter=true&facet_recovery=false&fulfillment_test_mode=grocery_opu_team_member_test&isDLP=false&keyword=Peanut+Butter+Cereal&offset=0&pageId=%2Fs%2FPeanut+Butter+Cereal&pricing_store_id=1306&store_ids=1306%2C3294%2C198%2C2775%2C2632&visitorId=0172C7C1A02802019D4E379FB6434C3C&include_sponsored_search_v2=true&ppatok=AOxT33a&platform=mobile&useragent=Mozilla%2F5.0+%28Linux%3B+Android+6.0%3B+Nexus+5+Build%2FMRA58N%29+AppleWebKit%2F537.36+%28KHTML%2C+like+Gecko%29+Chrome%2F83.0.4103.116+Mobile+Safari%2F537.36&excludes=available_to_promise_qualitative%2Cavailable_to_promise_location_qualitative&key=eb2551e4accc14f38cc42d32fbc2b2ea'\n",
    "item=''\n",
    "search_item =''\n",
    "products = []\n",
    "count = 0\n",
    "\n",
    "for key, value in items_dict.items():\n",
    "    \n",
    "    item = key\n",
    "    search_item = str(key) + \" \" + str(value)\n",
    "    \n",
    "    url = urlparse(url)\n",
    "    list_url = list(url)\n",
    "    #set new params\n",
    "    params = dict( (k, v if len(v)>1 else v[0] ) for k, v in parse_qs(url.query).items() )\n",
    "    params['include_sponsored_search_v2'] = 'false'\n",
    "    params['keyword'] = search_item\n",
    "    params['pageId'] = '/s/%s'%(search_item)\n",
    "\n",
    "\n",
    "    #update url\n",
    "    list_url[4] = urlencode(params)\n",
    "    url = urlunparse(list_url)\n",
    "    item = item\n",
    "    search_item = search_item \n",
    "    \n",
    "    #get url res\n",
    "    useragent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "    headers = {'User-Agent':useragent}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    json_str = res.text\n",
    "    js = json.loads(json_str)\n",
    "    js_list = list(js.values())\n",
    "    \n",
    "    try:\n",
    "        search_result = js_list[1]['items']['Item']\n",
    "    except:\n",
    "        print('%s : no result'%(item))\n",
    "    \n",
    "    getInfo(search_result)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
