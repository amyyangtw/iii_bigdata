{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立所有商品名稱 + 商品分類細項 的list\n",
    "\n",
    "### 1. pd.read_csv('自己的檔案路徑')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./dataset/keywords/keywords_LA1.csv')\n",
    "df_dict = df.set_index('product_name').to_dict()\n",
    "items_dict = df_dict['aisle']\n",
    "\n",
    "print(len(items_dict))\n",
    "#print(items_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得Product info Dict\n",
    "\n",
    "### 2. with open('product_info_自己負責的區.json', 'w') as fp:\n",
    "### 3. win的user 請改 soup = BeautifulSoup(req.text, \"lxml\")\n",
    "### 4. with open('product_info_LA1.json', 'a', encoding='utf-8') as fp:因為改為單筆寫入 舊的要記得刪掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(search_result):\n",
    "    for item_info in search_result:\n",
    "\n",
    "        product_info = {\n",
    "            \"keyword\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"brand\": \"\",\n",
    "            \"url\": \"\",\n",
    "            \"pic\": \"\",\n",
    "            \"price\": \"\",\n",
    "            \"category\": [],\n",
    "            \"star_ratings\": [],\n",
    "            \"at_a_glance\": [],\n",
    "            \"highlights\": [],\n",
    "            \"specifications\": {},\n",
    "            \"description\": \"\",\n",
    "            \"reviews\": []\n",
    "        }\n",
    "        \n",
    "        if (item_info.get('type')=='Collection Parent'):\n",
    "            continue\n",
    "            \n",
    "        p_name = item_info.get('title', 'NA')\n",
    "        p_brand = item_info.get('brand', 'NA')\n",
    "        p_price = lambda x:x['price'].get('formatted_current_price', 'NA') if item_info.get('price') else 'NA'\n",
    "        p_glances = item_info.get(\"wellness_merchandise_attributes\", 'NA')\n",
    "        p_description = item_info.get('description', 'NA')\n",
    "\n",
    "        #rating\n",
    "        p_ratings_s_avg = item_info.get('average_rating', 'NA')\n",
    "        p_ratings_s_cnt = item_info.get('total_reviews', 'NA')\n",
    "\n",
    "        p_url = lambda x: 'https://www.target.com'+x if item_info.get('url') else 'NA'\n",
    "        p_pic = lambda x: x.get('base_url')+x.get('primary') if item_info.get('images') else 'NA'\n",
    "        p_highlights = lambda x:x['soft_bullets'].get('bullets', 'NA') if item_info.get('soft_bullets') else 'NA' \n",
    "\n",
    "        #category\n",
    "        if item_info.get('url'):\n",
    "            try:\n",
    "                req = requests.get(p_url(item_info['url']))\n",
    "                #win的user 請改 soup = BeautifulSoup(req.text, \"lxml\")\n",
    "                soup = BeautifulSoup(req.text, \"html\")\n",
    "                p_category = soup.find(\"div\", {\"class\", \"h-text-sm h-padding-v-tiny\"}).text.strip(\"\\u200e\").split(\"/\")\n",
    "                product_info['category'] = p_category[1:]\n",
    "            except:\n",
    "                product_info['category'] = 'NA'\n",
    "        else:\n",
    "            product_info['category'] = 'NA'\n",
    "\n",
    "        #reviews\n",
    "        p_review = item_info.get(\"top_reviews\", 'NA')\n",
    "\n",
    "        product_info['keyword'] = item\n",
    "        product_info['name'] = p_name\n",
    "        product_info['url'] = p_url(item_info['url'])\n",
    "        product_info['brand'] = p_brand\n",
    "        product_info['pic'] = p_pic(item_info['images'][0])\n",
    "        product_info['price'] = p_price(item_info)\n",
    "        product_info['star_ratings'].append(p_ratings_s_avg) \n",
    "        product_info['star_ratings'].append(p_ratings_s_cnt) \n",
    "\n",
    "        #specifications\n",
    "        spec_list = [\"Contains\", \"Form\", \"State of Readiness\", \"Store\", \"Package Quantity\", \"Package type\", \"Net weight\"]\n",
    "        if item_info.get(\"bullet_description\"):\n",
    "            match=0\n",
    "            for i in spec_list:\n",
    "                for j in item_info[\"bullet_description\"]:\n",
    "                    j = re.sub(\"<.*?>\", \" \",j).strip(' ')\n",
    "                    if re.match(i, j.split(\": \")[0]):\n",
    "                        product_info[\"specifications\"][i] = j.split(\": \")[1]\n",
    "                        match+=1\n",
    "            if(match==0):\n",
    "                product_info[\"specifications\"]='NA'\n",
    "        else:\n",
    "            product_info[\"specifications\"]='NA'\n",
    "\n",
    "        #description\n",
    "        product_info['description'] = p_description\n",
    "        product_info['description'] = re.sub(\"<.*?>\", \" \",product_info['description'])\n",
    "\n",
    "        #reviews\n",
    "        if (p_review == \"NA\"):\n",
    "            product_info[\"reviews\"] = \"NA\"\n",
    "        else:\n",
    "            for rev in p_review:\n",
    "                review = re.sub('[\\r\\n\\t]', '', rev[\"review_text\"])\n",
    "                product_info[\"reviews\"].append(review)\n",
    "\n",
    "        #at_a_glance\n",
    "        if (p_glances=='NA'):\n",
    "            product_info['at_a_glance']= 'NA'\n",
    "        else:\n",
    "            for glance in p_glances:\n",
    "                product_info['at_a_glance'].append(glance[\"value_name\"])\n",
    "\n",
    "        #highlight\n",
    "        if (p_highlights(item_info)=='NA'):\n",
    "            product_info['highlights'] = 'NA'\n",
    "        else:\n",
    "            for highlight in p_highlights(item_info):\n",
    "                product_info['highlights'].append(highlight)\n",
    "\n",
    "        #products.append(product_info)\n",
    "        #print(product_info)\n",
    "        with open('product_info_LA1.json', 'a', encoding='utf-8') as fp:\n",
    "            global count\n",
    "            count+=1\n",
    "\n",
    "            if (count==1):\n",
    "                fp.write('[')\n",
    "                json.dump(product_info, fp, indent=4, ensure_ascii=False)\n",
    "                fp.write(',')\n",
    "            elif(count==8200):\n",
    "                json.dump(product_info, fp, indent=4, ensure_ascii=False)\n",
    "                fp.write(']')\n",
    "            else:\n",
    "                json.dump(product_info, fp, indent=4, ensure_ascii=False)\n",
    "                fp.write(',')\n",
    "\n",
    "            print(f'{count} finished.')\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析網址 + 更改參數 get info\n",
    "\n",
    "### 4. url = '自己的地點的url' (count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python_2020/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'redsky.target.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 finished.\n",
      "2 finished.\n",
      "3 finished.\n",
      "4 finished.\n",
      "5 finished.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n",
    "\n",
    "url = 'https://redsky.target.com/v2/plp/search/?channel=web&count=6&default_purchasability_filter=true&facet_recovery=false&fulfillment_test_mode=grocery_opu_team_member_test&isDLP=false&keyword=Peanut+Butter+Cereal&offset=0&pageId=%2Fs%2FPeanut+Butter+Cereal&pricing_store_id=1306&store_ids=1306%2C3294%2C198%2C2775%2C2632&visitorId=0172C7C1A02802019D4E379FB6434C3C&include_sponsored_search_v2=true&ppatok=AOxT33a&platform=mobile&useragent=Mozilla%2F5.0+%28Linux%3B+Android+6.0%3B+Nexus+5+Build%2FMRA58N%29+AppleWebKit%2F537.36+%28KHTML%2C+like+Gecko%29+Chrome%2F83.0.4103.116+Mobile+Safari%2F537.36&excludes=available_to_promise_qualitative%2Cavailable_to_promise_location_qualitative&key=eb2551e4accc14f38cc42d32fbc2b2ea'\n",
    "item=''\n",
    "search_item =''\n",
    "count = 0\n",
    "#products=[]\n",
    "no_result = []\n",
    "\n",
    "for key, value in items_dict.items():\n",
    "    \n",
    "    item = key\n",
    "    search_item = str(key) + \" \" + str(value)\n",
    "    \n",
    "    url = urlparse(url)\n",
    "    list_url = list(url)\n",
    "    #set new params\n",
    "    params = dict( (k, v if len(v)>1 else v[0] ) for k, v in parse_qs(url.query).items() )\n",
    "    params['include_sponsored_search_v2'] = 'false'\n",
    "    params['keyword'] = search_item\n",
    "    params['pageId'] = '/s/%s'%(search_item)\n",
    "\n",
    "\n",
    "    #update url\n",
    "    list_url[4] = urlencode(params)\n",
    "    url = urlunparse(list_url)\n",
    "    item = item\n",
    "    search_item = search_item \n",
    "    #print(search_item, url)\n",
    "    \n",
    "    #get url res\n",
    "    useragent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "    headers = {'User-Agent':useragent}\n",
    "    res = requests.get(url, headers=headers, verify=False)\n",
    "    \n",
    "    #check status code\n",
    "    if (res.status_code==200):\n",
    "        json_str = res.text\n",
    "        js = json.loads(json_str)\n",
    "        js_list = list(js.values())\n",
    "        \n",
    "        try:\n",
    "            search_result = js_list[1]['items']['Item']\n",
    "            #print(search_result)\n",
    "            getInfo(search_result)\n",
    "        except:\n",
    "            no_result.append(item)\n",
    "            print('%s : no result'%(item))\n",
    "\n",
    "    else:\n",
    "        no_result.append(item)\n",
    "        print('%s : no result'%(item))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
